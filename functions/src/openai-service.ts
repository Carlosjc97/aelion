/**
 * OpenAI Service - Generative Content with GPT-4o
 * Uses prompts designed by Ara for optimal token efficiency and structured output
 */

import * as admin from "firebase-admin";
import * as logger from "firebase-functions/logger";
import { config as firebaseConfig } from "firebase-functions";
import { createHash } from "node:crypto";
import { generateJson, ModelCaller } from "./adaptive/retryWrapper";
import {
  CalibrationQuizSchema,
  AdaptivePlanDraftSchema,
  ModuleAdaptiveSchema,
  CheckpointQuizSchema,
  RemedialBoosterSchema,
  EvaluationResultSchema,
  ModuleCountSchema,
} from "./adaptive/schemas";
import { validateOrThrow } from "./adaptive/validator";

/**
 * Detect domain type from topic for appropriate prompt customization
 */
function detectDomain(topic: string): string {
  const topicLower = topic.toLowerCase().trim();

  // Programming/Tech domains
  if (topicLower.includes("sql") || topicLower.includes("database") ||
      topicLower.includes("python") || topicLower.includes("javascript") ||
      topicLower.includes("java") || topicLower.includes("programming") ||
      topicLower.includes("code") || topicLower.includes("web") ||
      topicLower.includes("flutter") || topicLower.includes("react")) {
    return "programming";
  }

  // Language learning
  if (topicLower.includes("ingl√©s") || topicLower.includes("english") ||
      topicLower.includes("espa√±ol") || topicLower.includes("spanish") ||
      topicLower.includes("franc√©s") || topicLower.includes("french") ||
      topicLower.includes("language") || topicLower.includes("idioma") ||
      topicLower.includes("conversation")) {
    return "language";
  }

  // Mathematics
  if (topicLower.includes("matem√°ticas") || topicLower.includes("math") ||
      topicLower.includes("c√°lculo") || topicLower.includes("calculus") ||
      topicLower.includes("√°lgebra") || topicLower.includes("algebra") ||
      topicLower.includes("estad√≠stica") || topicLower.includes("statistics") ||
      topicLower.includes("geometr√≠a") || topicLower.includes("geometry")) {
    return "math";
  }

  // Business/Marketing
  if (topicLower.includes("marketing") || topicLower.includes("business") ||
      topicLower.includes("ventas") || topicLower.includes("sales") ||
      topicLower.includes("gesti√≥n") || topicLower.includes("management")) {
    return "business";
  }

  // Science
  if (topicLower.includes("f√≠sica") || topicLower.includes("physics") ||
      topicLower.includes("qu√≠mica") || topicLower.includes("chemistry") ||
      topicLower.includes("biolog√≠a") || topicLower.includes("biology")) {
    return "science";
  }

  return "general";
}

// Cache for API keys (one per type for load balancing)
const cachedOpenAIApiKeys: Record<string, string | null> = {
  primary: null,
  modules: null,
  quizzes: null,
  calibration: null,
};

/**
 * API Key routing strategy:
 * - primary: General endpoints and fallback
 * - modules: Module generation (heavy, long-running)
 * - quizzes: Checkpoint quizzes and evaluations
 * - calibration: Placement/calibration quizzes
 *
 * This distributes load across 4 API keys, increasing throughput from 10K TPM to 40K TPM
 */
type ApiKeyType = "primary" | "modules" | "quizzes" | "calibration";

function getApiKeyForEndpoint(endpointHint: string): ApiKeyType {
  const hint = endpointHint.toLowerCase();

  // Module generation endpoints
  if (hint.includes("module") && (hint.includes("generate") || hint.includes("adaptive"))) {
    return "modules";
  }

  // Quiz/checkpoint endpoints
  if (hint.includes("quiz") || hint.includes("checkpoint") || hint.includes("evaluation")) {
    return "quizzes";
  }

  // Calibration/placement endpoints
  if (hint.includes("calibration") || hint.includes("placement")) {
    return "calibration";
  }

  // Default to primary
  return "primary";
}

function resolveOpenAIApiKey(keyType: ApiKeyType = "primary"): string | undefined {
  // Check cache first
  if (cachedOpenAIApiKeys[keyType]) {
    return cachedOpenAIApiKeys[keyType]!;
  }

  // Try environment variables with specific names for each key type
  const envVarName = `OPENAI_API_KEY_${keyType.toUpperCase()}`;
  const specificEnvKey = process.env[envVarName]?.trim();
  if (specificEnvKey) {
    cachedOpenAIApiKeys[keyType] = specificEnvKey;
    logger.info(`Using ${envVarName} from environment variables`);
    return specificEnvKey;
  }

  // Fallback to generic OPENAI_API_KEY for backward compatibility
  const genericEnvKey = process.env.OPENAI_API_KEY?.trim();
  if (genericEnvKey) {
    cachedOpenAIApiKeys[keyType] = genericEnvKey;
    logger.info("Using OPENAI_API_KEY from environment variables as fallback");
    return genericEnvKey;
  }

  // Last resort: try Firebase config (deprecated in v2, will likely fail)
  try {
    const runtimeConfig = firebaseConfig();

    // Try specific key for this type
    const specificKey = runtimeConfig.openai?.[`api_key_${keyType}`];
    if (specificKey && typeof specificKey === "string") {
      const trimmedKey = specificKey.trim();
      cachedOpenAIApiKeys[keyType] = trimmedKey;
      return trimmedKey;
    }

    // Fallback to primary key
    const fallbackKey =
      runtimeConfig.openai?.api_key_primary ||
      runtimeConfig.openai?.key ||
      runtimeConfig.openai?.api_key ||
      runtimeConfig.openai?.apiKey ||
      runtimeConfig.OPENAI?.key ||
      runtimeConfig.OPENAI?.api_key;

    const configKey = typeof fallbackKey === "string" ? fallbackKey.trim() : undefined;

    if (configKey) {
      cachedOpenAIApiKeys[keyType] = configKey;
      return configKey;
    }
  } catch (error) {
    logger.debug("Firebase runtime config unavailable for OpenAI key", {
      keyType,
      error: error instanceof Error ? error.message : String(error),
    });
  }

  return undefined;
}

// OpenAI API types
interface OpenAIMessage {
  role: "system" | "user" | "assistant";
  content: string;
}

interface OpenAIResponse {
  id: string;
  object: string;
  created: number;
  model: string;
  choices: Array<{
    index: number;
    message: OpenAIMessage;
    finish_reason: string;
  }>;
  usage: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
}

// Calibration Quiz types
interface CalibrationQuestion {
  question: string;
  options: string[]; // ["A: Option 1", "B: Option 2", ...]
  correct: string; // "A", "B", "C", or "D"
  difficulty: "easy" | "medium" | "hard";
}

interface CalibrationSchemaQuestion {
  id: string;
  stem: string;
  options: {
    A: string;
    B: string;
    C: string;
    D: string;
  };
  correct: "A" | "B" | "C" | "D";
  difficulty: "easy" | "medium" | "hard";
  skillTag: string;
  explanation: string;
  motivation: string;
}

interface CalibrationQuizPayload {
  topic: string;
  language: string;
  questions: CalibrationSchemaQuestion[];
}

// Module types
interface LessonChallenge {
  desc: string;
  expected: string;
}

interface ModuleLesson {
  title: string;
  content: string; // Markdown
  estimatedTime: number; // minutes
  hook?: string;
  explanation?: string | string[];
  reto?: LessonChallenge;
  takeaway?: string;
}

interface ModuleChallenge {
  description: string;
  expectedOutput: string;
}

interface ModuleTestQuestion {
  question: string;
  options: string[];
  correct: string;
  difficulty?: "easy" | "medium" | "hard";
  rationale?: string;
}

interface ModulePlanOverviewItem {
  moduleNumber: number;
  title: string;
  objective: string;
  focus: string;
}

interface GeneratedModule {
  moduleNumber: number;
  title: string;
  lessons: ModuleLesson[];
  challenge: ModuleChallenge;
  test: ModuleTestQuestion[];
  planOverview?: ModulePlanOverviewItem[];
  promptVersion?: string;
}

export type Band = "basic" | "intermediate" | "advanced";

export interface LearnerState {
  level_band: Band;
  skill_mastery: Record<string, number>;
  history: {
    passedModules: number[];
    failedModules: number[];
    commonErrors: string[];
  };
  target: string;
  visitedLessons?: Record<string, boolean>; // Keys: "topic_m1_l0", "topic_m1_l1", etc.
}

export interface MCQ {
  id: string;
  stem: string;
  options: { A: string; B: string; C: string; D: string };
  correct: "A" | "B" | "C" | "D";
  skillTag: string;
  rationale: string;
}

export type LessonType =
  | "welcome_summary"
  | "diagnostic_quiz"
  | "guided_practice"
  | "activity"
  | "mini_game"
  | "theory_refresh"
  | "applied_project"
  | "reflection";

export interface Lesson {
  title: string;
  hook: string;
  lessonType: LessonType;
  theory: string;
  exampleGlobal: string;
  practice: { prompt: string; expected: string };
  microQuiz: MCQ[];
  hint?: string;
  motivation?: string;
  takeaway: string;
}

export interface ModuleOut {
  moduleNumber: number;
  title: string;
  durationMinutes: number;
  skillsTargeted: string[];
  lessons: Lesson[];
  challenge: { desc: string; expected: string; rubric: string[] };
  checkpointBlueprint: {
    items: Array<{ id: string; skillTag: string; type: "mcq" }>;
    targetReliability: "low" | "medium" | "high";
  };
}

export interface AdaptivePlanDraft {
  suggestedModules: Array<{
    moduleNumber: number;
    title: string;
    skills: string[];
    objective: string;
  }>;
  skillCatalog: Array<{ tag: string; desc: string }>;
  notes: string;
}

export interface CheckpointQuizItem {
  id: string;
  stem: string;
  options: { A: string; B: string; C: string; D: string };
  correct: "A" | "B" | "C" | "D";
  skillTag: string;
  rationale: string;
  difficulty: "easy" | "medium" | "hard";
}

export interface CheckpointQuiz {
  module: number;
  items: CheckpointQuizItem[];
}

export interface EvaluationResult {
  score: number;
  masteryDelta: Record<string, number>;
  updatedMastery: Record<string, number>;
  weakSkills: string[];
  recommendation: "advance" | "remedial";
}

export interface RemedialBooster {
  boosterFor: string[];
  lessons: Lesson[];
  microQuiz: MCQ[];
}

type PromptVariant = "global_curiosity_v1" | "global_curiosity_v2";

const promptVariants: PromptVariant[] = ["global_curiosity_v1", "global_curiosity_v2"];

function buildCuriousSystemMessage(topic: string): string {
  const normalizedTopic = topic.trim().length > 0 ? topic.trim() : "aprendizaje adaptativo";
  return [
    `Eres un tutor IA experto en ${normalizedTopic}.`,
    "Hablas en tono cercano y universal, mezclando ejemplos curiosos de todo el mundo y escenarios ficticios inventados (startups islandesas estudiando auroras boreales, equipos en Singapur optimizando datos de eclipses, cooperativas en Kenia monitoreando energ√≠a solar submarina, apps de viajes que analizan volcanes marcianos).",
    "Tu misi√≥n es generar contenido espec√≠fico, accionable y motivador que despierte curiosidad inmediata con contextos globales y multiculturales.",
    "Nunca incluyes notas fuera del JSON solicitado y siempre devuelves estructuras v√°lidas."
  ].join(" ");
}

export interface OutlineTweakResult {
  modules: ModulePlanOverviewItem[];
  recommendedModules: number;
  summary: string;
  promptVersion: string;
}

export interface ChallengeValidationResult {
  score: number;
  feedback: string;
  passed: boolean;
  promptVersion: string;
}

export async function generateGateHints(params: {
  topic: string;
  moduleNumber: number;
  lang: string;
  errors?: string[];
  userId?: string;
  promptVersionOverride?: PromptVariant;
}): Promise<string[]> {
  const { topic, moduleNumber, lang, errors = [], userId, promptVersionOverride } = params;
  const language = lang === "es" ? "es" : "en";
  const promptVersion =
    promptVersionOverride ?? determinePromptVariant(userId, "gate_hints");

  const errorSummary = errors.length > 0 ? errors.join(", ") : "sin etiquetas previas";
  const prompt = [
    `Topic: ${topic}`,
    `Module: ${moduleNumber}`,
    `Language: ${language}`,
    `Detected mistakes: ${errorSummary}`,
    "Modo simplificado (hints:true): genera 3 a 4 consejos accionables para ayudar al estudiante a aprobar el gate quiz.",
    "Cada hint debe mezclar escenarios globales o inventados (startups islandesas, apps de viajes que analizan eclipses, laboratorios en Nairobi) y explicar concretamente que practicar.",
    "Manten cada hint <= 40 palabras y termina con mini llamada a la accion (ej. 'Practica explicar...').",
    'Responde SOLO JSON {"hints":["hint 1","hint 2","hint 3"]}.',
  ].join("\n");

  const systemMessage = buildCuriousSystemMessage(topic);
  const messages: OpenAIMessage[] = [
    { role: "system", content: `${systemMessage} Devuelve solo JSON valido.` },
    { role: "user", content: prompt },
  ];

  try {
    const response = await callOpenAI(messages, {
      temperature: 0.45,
      maxTokens: 700,
      model: "gpt-4o-mini",
      timeoutMs: 20000,
      endpointHint: "gate-hints",
    });

    const content = response.choices[0].message.content;
    const parsed = safeJSONParse(content, 1);

    const hints = Array.isArray(parsed?.hints)
      ? parsed.hints
          .map((hint: unknown) => (typeof hint === "string" ? hint.trim() : ""))
          .filter((hint: string) => hint.length > 0)
      : [];

    if (!hints.length) {
      throw new Error("Invalid hints payload");
    }

    await logOpenAiUsage({
      endpoint: "generateGateHints",
      model: response.model,
      promptTokens: response.usage?.prompt_tokens ?? 0,
      completionTokens: response.usage?.completion_tokens ?? 0,
      topic,
      lang: language,
      userId,
      moduleNumber,
      promptVersion,
    });

    return hints;
  } catch (error) {
    logger.error("Failed to generate gate hints", {
      topic,
      moduleNumber,
      error: error instanceof Error ? error.message : String(error),
    });
    throw error;
  }
}

/**
 * Safe JSON parse with retry
 * OpenAI sometimes returns malformed JSON - this validates and retries
 */
function safeJSONParse(content: string, retryAttempt: number): any {
  try {
    // Try to extract JSON from markdown code blocks if present
    let cleaned = content.trim();
    if (cleaned.startsWith("```json")) {
      cleaned = cleaned.replace(/```json\n?/g, "").replace(/```\n?$/g, "");
    } else if (cleaned.startsWith("```")) {
      cleaned = cleaned.replace(/```\n?/g, "");
    }

    const parsed = JSON.parse(cleaned);
    return parsed;
  } catch (error) {
    logger.warn(`JSON parse failed (attempt ${retryAttempt})`, {
      error: error instanceof Error ? error.message : String(error),
      contentPreview: content.substring(0, 200),
    });
    throw new Error(`Invalid JSON from OpenAI: ${error instanceof Error ? error.message : String(error)}`);
  }
}

function determinePromptVariant(userId?: string, seed = "default"): PromptVariant {
  if (!userId) {
    return promptVariants[0];
  }

  const hash = createHash("sha256")
    .update(`${seed}:${userId}`)
    .digest("hex");
  const numeric = parseInt(hash.substring(0, 8), 16);
  const index = numeric % promptVariants.length;
  return promptVariants[index];
}

interface UsageLogInput {
  userId?: string;
  endpoint: string;
  model: string;
  promptTokens: number;
  completionTokens: number;
  topic?: string;
  lang?: string;
  moduleNumber?: number;
  band?: string;
  promptVersion?: string;
  cacheHit?: boolean;
  extra?: Record<string, unknown>;
}

async function logOpenAiUsage(input: UsageLogInput): Promise<void> {
  const {
    userId = "system",
    endpoint,
    model,
    promptTokens,
    completionTokens,
    topic,
    lang,
    moduleNumber,
    band,
    promptVersion,
    cacheHit = false,
    extra = {},
  } = input;

  const totalTokens =
    promptTokens + completionTokens > 0
      ? promptTokens + completionTokens
      : 0;

  const payload: Record<string, unknown> = {
    timestamp: admin.firestore.FieldValue.serverTimestamp(),
    userId,
    endpoint,
    model,
    tokens: totalTokens,
    promptTokens,
    completionTokens,
    estimatedCost: estimateCost({
      prompt: promptTokens,
      completion: completionTokens,
    }),
    topic,
    lang,
    moduleNumber,
    band,
    cacheHit,
    promptVersion,
    ...extra,
  };

  Object.keys(payload).forEach((key) => {
    if (payload[key] === undefined) {
      delete payload[key];
    }
  });

  await admin.firestore().collection("openai_usage").add(payload);
}

interface ModelCallMetadata {
  model: string;
  promptTokens: number;
  completionTokens: number;
}

interface ModelCallResult extends ModelCallMetadata {
  content: string;
}

const OPENAI_CHAT_URL =
  (process.env.OPENAI_BASE_URL?.replace(/\/+$/, "") || "https://api.openai.com") +
  "/v1/chat/completions";
const MODEL_TIMEOUT_MS = 180000; // 180 segundos (3 minutos) - temporal mientras se optimiza contenido
const MODEL_MAX_RETRIES = 3;

function sleep(ms: number): Promise<void> {
  return new Promise((resolve) => setTimeout(resolve, ms));
}

async function callModelRaw(args: {
  system: string;
  user: string;
  model: string;
  temperature?: number;
  max_tokens?: number;
  response_format?: unknown;
  endpointHint?: string;
}): Promise<ModelCallResult> {
  const keyType = getApiKeyForEndpoint(args.endpointHint || "primary");
  const apiKey = resolveOpenAIApiKey(keyType);
  if (!apiKey) {
    throw new Error("OPENAI_API_KEY not configured");
  }

  let attempt = 0;
  let lastError: unknown;
  let responseFormatEnabled = Boolean(args.response_format);

  while (attempt < MODEL_MAX_RETRIES) {
    attempt++;
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), MODEL_TIMEOUT_MS);

    try {
      const payload: Record<string, unknown> = {
        model: args.model,
        temperature: args.temperature ?? 0.6,
        max_tokens: args.max_tokens ?? 1600,
        messages: [
          { role: "system", content: args.system },
          { role: "user", content: args.user },
        ],
      };
      const shouldAttachResponseFormat = responseFormatEnabled && Boolean(args.response_format);
      if (shouldAttachResponseFormat && args.response_format) {
        payload.response_format = args.response_format;
      }

      const response = await fetch(OPENAI_CHAT_URL, {
        method: "POST",
        signal: controller.signal,
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${apiKey}`,
        },
        body: JSON.stringify(payload),
      });

      clearTimeout(timeoutId);

      if (!response.ok) {
        const body = await response.text();
        const retriable = response.status === 429 || (response.status >= 500 && response.status < 600);
        const structuredOutputRejected =
          shouldAttachResponseFormat &&
          response.status === 400 &&
          /response_format/i.test(body);
        if (structuredOutputRejected) {
          responseFormatEnabled = false;
          logger.warn("Structured output not supported for model, retrying without response_format", {
            model: args.model,
            status: response.status,
            body,
          });
          clearTimeout(timeoutId);
          attempt -= 1;
          continue;
        }
        lastError = new Error(`OpenAI HTTP ${response.status}: ${body}`);
        if (retriable && attempt < MODEL_MAX_RETRIES) {
          const delay = Math.min(2000 * 2 ** (attempt - 1), 10000) + Math.floor(Math.random() * 400);
          await sleep(delay);
          continue;
        }
        throw lastError;
      }

      const json = (await response.json()) as OpenAIResponse;
      const content = json?.choices?.[0]?.message?.content ?? "";
      if (!content) {
        throw new Error("Empty completion content");
      }

      return {
        content,
        model: json.model ?? args.model,
        promptTokens: json.usage?.prompt_tokens ?? 0,
        completionTokens: json.usage?.completion_tokens ?? 0,
      };
    } catch (error) {
      clearTimeout(timeoutId);
      lastError = error;
      const isAbort = (error as Error)?.name === "AbortError";
      if (isAbort && attempt < MODEL_MAX_RETRIES) {
        const delay = Math.min(2000 * 2 ** (attempt - 1), 10000) + Math.floor(Math.random() * 400);
        await sleep(delay);
        continue;
      }
      throw error;
    }
  }

  throw lastError ?? new Error("Unknown OpenAI error");
}

function createTrackedModelCaller() {
  let lastMetadata: ModelCallMetadata | undefined;
  const caller: ModelCaller = async (args) => {
    const result = await callModelRaw(args);
    lastMetadata = {
      model: result.model,
      promptTokens: result.promptTokens,
      completionTokens: result.completionTokens,
    };
    return result.content;
  };

  return {
    caller,
    getLastMetadata: () => lastMetadata,
  };
}

/**
 * Call OpenAI API with retry logic
 */
async function callOpenAI(
  messages: OpenAIMessage[],
  options: {
    temperature?: number;
    maxTokens?: number;
    model?: string;
    timeoutMs?: number;
    endpointHint?: string;
  } = {}
): Promise<OpenAIResponse> {
  const keyType = getApiKeyForEndpoint(options.endpointHint || "primary");
  const apiKey = resolveOpenAIApiKey(keyType);
  if (!apiKey) {
    throw new Error("OPENAI_API_KEY not configured");
  }

  const model = options.model || "gpt-4o";
  const temperature = options.temperature ?? 0.7;
  const maxTokens = options.maxTokens || 4000;
  let responseFormatEnabled = true;

  const maxRetries = 3;
  let lastError: Error | null = null;

  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      const controller = new AbortController();
      const timeout = setTimeout(() => controller.abort(), options.timeoutMs ?? 60000);

      const payload: Record<string, unknown> = {
        model,
        messages,
        temperature,
        max_tokens: maxTokens,
      };
      if (responseFormatEnabled) {
        payload.response_format = { type: "json_object" };
      }

      const response = await fetch("https://api.openai.com/v1/chat/completions", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "Authorization": `Bearer ${apiKey}`,
        },
        body: JSON.stringify(payload),
        signal: controller.signal,
      }).finally(() => clearTimeout(timeout));

      if (!response.ok) {
        const errorText = await response.text();
        if (
          responseFormatEnabled &&
          response.status === 400 &&
          /response_format/i.test(errorText)
        ) {
          responseFormatEnabled = false;
          logger.warn("Structured output rejected by model, retrying without response_format", {
            model,
            attempt,
            error: errorText,
          });
          attempt -= 1;
          continue;
        }
        throw new Error(`OpenAI API error: ${response.status} - ${errorText}`);
      }

      const data = await response.json() as OpenAIResponse;

      logger.info(`OpenAI call successful (attempt ${attempt})`, {
        model,
        tokens: data.usage.total_tokens,
      });

      return data;
    } catch (error) {
      lastError = error instanceof Error ? error : new Error(String(error));
      logger.warn(`OpenAI call failed (attempt ${attempt}/${maxRetries})`, {
        error: lastError.message,
      });

      if (attempt < maxRetries) {
        // Exponential backoff
        await new Promise(resolve => setTimeout(resolve, 1000 * Math.pow(2, attempt)));
      }
    }
  }

  throw lastError || new Error("OpenAI call failed after retries");
}

/**
 * Generate calibration quiz (10 questions)
 *
 * Prompt by Ara - optimized for token efficiency
 */
export async function generateCalibrationQuiz(params: {
  topic: string;
  lang: string;
  userId?: string;
  promptVersionOverride?: PromptVariant;
}): Promise<CalibrationQuestion[]> {
  const { topic, lang, userId, promptVersionOverride } = params;
  const language = lang === "es" ? "es" : "en";
  const domainType = detectDomain(topic);
  const promptVersion =
    promptVersionOverride ?? determinePromptVariant(userId, "calibration");

  const scenarioFlavor =
    domainType === "programming"
      ? "deploys globales, analisis de datos de eclipses, squads que interpretan telemetria de satelites"
      : domainType === "business"
        ? "pitch decks futuristas, growth para ferias de ciencia en Singapur, alianzas con startups islandesas"
        : "laboratorios creativos, misiones cientificas ficticias y proyectos interculturales";

  const tracker = createTrackedModelCaller();

  try {
    const quiz = await generateJson<CalibrationQuizPayload>(
      tracker.caller,
      CalibrationQuizSchema.$id,
      CALIBRATION_SYSTEM_PROMPT,
      buildCalibrationUserPrompt({
        topic,
        language,
        scenarioFlavor,
      }),
      "gpt-4o-mini",
      0.7,
      2400,
      MODEL_SCHEMA_FORMAT("CalibrationQuiz", CalibrationQuizSchema),
      3,
      "calibration",
    );

    const normalized = quiz.questions.map((question, index) => {
      const optionsArray = formatCalibrationOptions(question.options);
      if (optionsArray.length !== 4) {
        throw new Error(`Invalid options in calibration quiz at index ${index}`);
      }
      return {
        question: question.stem,
        options: optionsArray,
        correct: question.correct,
        difficulty: question.difficulty,
      } satisfies CalibrationQuestion;
    });

    if (normalized.length !== 10) {
      throw new Error(`Expected 10 questions, got ${normalized.length}`);
    }

    const meta = tracker.getLastMetadata();

    await logOpenAiUsage({
      endpoint: "generateCalibrationQuiz",
      model: meta?.model ?? "gpt-4o-mini",
      promptTokens: meta?.promptTokens ?? 0,
      completionTokens: meta?.completionTokens ?? 0,
      topic,
      lang: language,
      userId,
      promptVersion,
    });

    logger.info("Generated calibration quiz", {
      topic,
      lang: language,
      numQuestions: normalized.length,
      tokens: (meta?.promptTokens ?? 0) + (meta?.completionTokens ?? 0),
      promptVersion,
    });

    return normalized;
  } catch (error) {
    logger.error("Failed to generate calibration quiz", {
      topic,
      lang: language,
      error: error instanceof Error ? error.message : String(error),
    });
    throw error;
  }
}
/**
 * Generate adaptive module
 *
 * Prompt by Ara - includes user weaknesses and performance
 */
export async function generateModule(params: {
  moduleNumber: number;
  topic: string;
  band: string;
  lang: string;
  errors?: string[];
  previousScore?: number;
  userId?: string;
  promptVersionOverride?: PromptVariant;
}): Promise<GeneratedModule> {
  const {
    moduleNumber,
    topic,
    band,
    lang,
    errors = [],
    previousScore,
    userId,
    promptVersionOverride,
  } = params;

  const language = lang === "es" ? "es" : "en";
  const domainType = detectDomain(topic);
  const promptVersion =
    promptVersionOverride ?? determinePromptVariant(userId, "module");

  const errorSummary = errors.length > 0 ? errors.join(", ") : "sin gaps declarados";
  const scoreSummary =
    typeof previousScore === "number"
      ? `${previousScore}%`
      : "sin intento previo";

  const planInstruction = moduleNumber === 1
    ? "Define planOverview con totalModules ENTRE 4 Y 12 (elige el numero optimo segun complejidad: 4-5 si el tema es basico, 10-12 si es tecnico). Cada item requiere moduleNumber, title, objective y focus hiper especifico."
    : "Solo incluye planOverview si debes ajustarlo y mant√©n consistencia con modulos previos.";

  const curiosityExamples = domainType === "programming"
    ? "squads de Islandia que convierten datos de auroras en dashboards, equipos de Singapur que predicen bugs con IA, comunidades africanas que monitorean energia solar submarina"
    : "laboratorios de growth en Nairobi, agencias islandesas que miden turismo espacial, cooperativas ficticias que usan IA para mapear arrecifes";

  const prompt = [
    `Usuario nivel ${band} aprendiendo "${topic}".`,
    `Idioma del contenido: ${language}.`,
    `Errores o gaps detectados: ${errorSummary}.`,
    `Ultimo score disponible: ${scoreSummary}.`,
    "Decide el numero total de modulos optimo (4-12) y asegurate de que cada modulo escale complejidad gradualmente.",
    `Genera UNICAMENTE el modulo ${moduleNumber} reforzando los gaps listados.`,
    "Genera 3-5 lecciones breves (~5 min c/u) segun la dificultad real del tema.",
    "Cada leccion debe incluir:",
    "- title claro y accionable.",
    "- hook de ~30 segundos con escenario global o inventado (ej. startups islandesas, apps de viajes que analizan eclipses, laboratorios en Singapur).",
    "- explanation en Markdown con 4-6 bullets densos (minimo 250 palabras combinadas) mezclando ejemplos reales y ficticios.",
    "- reto interactivo (`reto.desc`) describiendo lo que el usuario debe crear y `reto.expected` con placeholders listos para validar (ej. Dear [Name] ...).",
    "- takeaway motivador con emoji (ej. 'Comparte tu hallazgo en tu squad global üöÄ').",
    `Incluye micro historias variadas (LATAM + Asia + escenarios imaginarios) inspiradas en ${curiosityExamples} para despertar curiosidad inmediata.`,
    'Agrega test final con 5-7 preguntas multiple choice, opciones etiquetadas "A:"..."D:", campo "correct" con letra y "difficulty" apropiado.',
    "Entrega tambien un challenge global del modulo (`challenge.description` y `challenge.expectedOutput`) que resuma la habilidad clave.",
    "Tono: habla de 'tu', estilo amigo maker global, mezcla datos, humor ligero y foco accionable.",
    planInstruction,
    `Responde SOLO JSON valido con esta forma: {
  "moduleNumber": number,
  "title": string,
  "lessons": [{"title","hook","explanation","reto":{"desc","expected"},"takeaway","estimatedTime"}],
  "challenge": {"description":"...", "expectedOutput":"..."},
  "test": [{"question","options","correct","difficulty","rationale"}],
  "planOverview": [{"moduleNumber":4,"title":"...","objective":"...","focus":"..."}]
}.`,
  ].join("\n");

  const systemMessage = buildCuriousSystemMessage(topic);

  const messages: OpenAIMessage[] = [
    { role: "system", content: `${systemMessage} No agregues notas fuera del JSON.` },
    { role: "user", content: prompt },
  ];

  try {
    const response = await callOpenAI(messages, {
      temperature: 0.7,
      maxTokens: 3000,
      model: "gpt-4o",
      timeoutMs: 60000,
      endpointHint: "module-generate",
    });

    const content = response.choices[0].message.content;
    const parsed = safeJSONParse(content, 1);

    if (!parsed || typeof parsed !== "object") {
      throw new Error("Invalid module structure from OpenAI");
    }

    if (!Array.isArray(parsed.lessons)) {
      throw new Error("Module lessons missing from OpenAI response");
    }

    const normalizedLessons: ModuleLesson[] = parsed.lessons.map((lesson: any, index: number) => {
      const hook = typeof lesson?.hook === "string" ? lesson.hook : "";
      const rawExplanation = lesson?.explanation ?? lesson?.content ?? "";
      const explanation = Array.isArray(rawExplanation)
        ? rawExplanation.join("\n- ")
        : rawExplanation?.toString() ?? "";

      const retoRaw = lesson?.reto ?? lesson?.challenge ?? {};
      const reto: LessonChallenge | undefined =
        retoRaw && (retoRaw.desc || retoRaw.expected || retoRaw.expectedOutput)
          ? {
            desc: (retoRaw.desc ?? retoRaw.description ?? "").toString(),
            expected: (retoRaw.expected ?? retoRaw.expectedOutput ?? "").toString(),
          }
          : undefined;

      const takeaway = typeof lesson?.takeaway === "string" ? lesson.takeaway : "";
      const estimatedTime = typeof lesson?.estimatedTime === "number"
        ? lesson.estimatedTime
        : typeof lesson?.duration === "number"
          ? lesson.duration
          : 5;

      return {
        title: lesson?.title?.toString() ?? `Leccion ${index + 1}`,
        content: explanation,
        estimatedTime,
        hook,
        explanation,
        reto,
        takeaway,
      };
    });

    const lessonChallenge = normalizedLessons.find((lesson) => lesson.reto && lesson.reto.desc && lesson.reto.expected)?.reto;

    const moduleChallenge: ModuleChallenge = {
      description: parsed?.challenge?.description
        ?? parsed?.challenge?.desc
        ?? lessonChallenge?.desc
        ?? "Reto practico",
      expectedOutput: parsed?.challenge?.expectedOutput
        ?? parsed?.challenge?.expected
        ?? lessonChallenge?.expected
        ?? "",
    };

    const planOverview = Array.isArray(parsed.planOverview)
      ? parsed.planOverview.map((item: any, idx: number) => ({
        moduleNumber: typeof item?.moduleNumber === "number" ? item.moduleNumber : idx + 1,
        title: item?.title?.toString() ?? `Modulo ${idx + 1}`,
        objective: item?.objective?.toString() ?? item?.summary?.toString() ?? "",
        focus: item?.focus?.toString() ?? item?.theme?.toString() ?? "",
      }))
      : undefined;

    const normalizedTest: ModuleTestQuestion[] = Array.isArray(parsed.test)
      ? parsed.test.map((question: any, idx: number) => {
        const options = Array.isArray(question?.options)
          ? question.options.map((option: any) => option?.toString() ?? "").filter(Boolean)
          : [];

        return {
          question: question?.question?.toString() ?? `Pregunta ${idx + 1}`,
          options,
          correct: question?.correct?.toString() ?? "A",
          difficulty: question?.difficulty,
          rationale: question?.rationale?.toString(),
        };
      }).filter((q: ModuleTestQuestion) => q.options.length >= 4)
      : [];

    const module: GeneratedModule = {
      moduleNumber: typeof parsed.moduleNumber === "number" ? parsed.moduleNumber : moduleNumber,
      title: parsed?.title?.toString() ?? `Modulo ${moduleNumber}`,
      lessons: normalizedLessons,
      challenge: moduleChallenge,
      test: normalizedTest,
      planOverview,
      promptVersion,
    };

    const promptTokens = response.usage?.prompt_tokens ?? 0;
    const completionTokens = response.usage?.completion_tokens ?? 0;

    await logOpenAiUsage({
      endpoint: "generateModule",
      model: response.model,
      promptTokens,
      completionTokens,
      topic,
      lang: language,
      moduleNumber: module.moduleNumber,
      band,
      userId,
      promptVersion,
    });

    logger.info("Generated module", {
      moduleNumber: module.moduleNumber,
      topic,
      band,
      lang: language,
      numLessons: module.lessons.length,
      numTestQuestions: module.test.length,
      tokens: response.usage.total_tokens,
      promptVersion,
    });

    return module;
  } catch (error) {
    logger.error("Failed to generate module", {
      moduleNumber,
      topic,
      band,
      error: error instanceof Error ? error.message : String(error),
    });
    throw error;
  }
}
/**
 * Estimate cost of generation
 * GPT-4o pricing: $2.50 / 1M input tokens, $10.00 / 1M output tokens
 */
export function estimateCost(tokens: { prompt: number; completion: number }): number {
  const inputCost = (tokens.prompt / 1_000_000) * 2.50;
  const outputCost = (tokens.completion / 1_000_000) * 10.00;
  return inputCost + outputCost;
}

function formatCalibrationOptions(
  options: CalibrationSchemaQuestion["options"],
): string[] {
  const orderedKeys: Array<keyof CalibrationSchemaQuestion["options"]> = ["A", "B", "C", "D"];
  return orderedKeys
    .map((key) => `${key}: ${options[key]?.trim() ?? ""}`.trim())
    .filter((entry) => entry.length > 3);
}

export async function tweakOutlinePlan(params: {
  topic: string;
  lang: string;
  gaps: string[];
  outlineSummary: string;
  userId?: string;
  promptVersionOverride?: PromptVariant;
}): Promise<OutlineTweakResult> {
  const { topic, lang, gaps, outlineSummary, userId, promptVersionOverride } = params;
  const language = lang === "es" ? "es" : "en";
  const promptVersion =
    promptVersionOverride ?? determinePromptVariant(userId, "outline_tweak");

  const gapSummary = gaps.length > 0 ? gaps.join(", ") : "sin gaps declarados";

  const prompt = [
    `Topic: "${topic}".`,
    `Language: ${language}.`,
    `Detected gaps: ${gapSummary}.`,
    "Current outline summary:",
    outlineSummary,
    "Reordena y ajusta el plan para cubrir los gaps. Decide el numero optimo de modulos (entre 4 y 12) segun complejidad.",
    "Cada modulo debe incluir: moduleNumber, title breve con gancho curioso/global, objective accionable y focus que mencione el gap o skill (ej. 'Storytelling con datos polares').",
    "Escala dificultad de forma progresiva y mezcla ejemplos de varias regiones/escenarios inventados (startups islandesas, apps de viajes que leen eclipses, cooperativas en Nairobi).",
    'Devuelve SOLO JSON con la forma {"recommendedModules":number,"modules":[{"moduleNumber":1,"title":"...","objective":"...","focus":"..."}],"summary":"explica personalizacion en <=2 frases"}.',
    "La summary debe mencionar por que cambio el plan y destacar un hook global.",
  ].join("\n");

  const systemMessage = buildCuriousSystemMessage(topic);

  const messages: OpenAIMessage[] = [
    { role: "system", content: `${systemMessage} Responde en ${language === "es" ? "espanol" : "English"} y no agregues comentarios fuera del JSON.` },
    { role: "user", content: prompt },
  ];

  try {
    const response = await callOpenAI(messages, {
      temperature: 0.4,
      maxTokens: 1500,
      model: "gpt-4o",
      timeoutMs: 40000,
      endpointHint: "adaptive-module-plan",
    });

    const content = response.choices[0].message.content;
    const parsed = safeJSONParse(content, 1);

    const recommendedModulesRaw = parsed?.recommendedModules;
    const recommendedModules =
      typeof recommendedModulesRaw === "number"
        ? Math.max(4, Math.min(12, Math.round(recommendedModulesRaw)))
        : Math.max(4, Math.min(12, Array.isArray(parsed?.modules) ? parsed.modules.length : 6));

    const modules = Array.isArray(parsed?.modules)
      ? parsed.modules.map((item: any, idx: number) => ({
        moduleNumber: typeof item?.moduleNumber === "number" ? item.moduleNumber : idx + 1,
        title: item?.title?.toString() ?? `Modulo ${idx + 1}`,
        objective: item?.objective?.toString() ?? item?.summary?.toString() ?? "",
        focus: item?.focus?.toString() ?? item?.priority?.toString() ?? "",
      }))
      : [];

    const summary = parsed?.summary?.toString() ?? "";

    await logOpenAiUsage({
      endpoint: "tweakOutlinePlan",
      model: response.model,
      promptTokens: response.usage?.prompt_tokens ?? 0,
      completionTokens: response.usage?.completion_tokens ?? 0,
      topic,
      lang: language,
      userId,
      promptVersion,
    });

    return {
      modules,
      recommendedModules,
      summary,
      promptVersion,
    };
  } catch (error) {
    logger.error("Failed to tweak outline plan", {
      topic,
      gaps,
      error: error instanceof Error ? error.message : String(error),
    });
    throw error;
  }
}

export async function validateChallengeResponse(params: {
  topic: string;
  lang: string;
  challengeDesc: string;
  expected: string;
  answer: string;
  userId?: string;
  promptVersionOverride?: PromptVariant;
}): Promise<ChallengeValidationResult> {
  const { topic, lang, challengeDesc, expected, answer, userId, promptVersionOverride } = params;
  const language = lang === "es" ? "es" : "en";
  const promptVersion =
    promptVersionOverride ?? determinePromptVariant(userId, "challenge_validation");

  const prompt = [
    `Evalua la respuesta del estudiante para el reto sobre "${topic}".`,
    `Descripcion del reto: ${challengeDesc}`,
    `Respuesta esperada: ${expected}`,
    `Respuesta del estudiante: ${answer}`,
    "Regresa JSON con {\"score\":0-100,\"feedback\":\"texto corto\",\"passed\":true|false}.",
    "Considera creatividad, alineacion con esperado y claridad.",
  ].join("\n");

  const systemMessage = buildCuriousSystemMessage(topic);

  const messages: OpenAIMessage[] = [
    { role: "system", content: `${systemMessage} Evalua en ${language === "es" ? "espanol" : "English"} y no incluyas texto fuera del JSON.` },
    { role: "user", content: prompt },
  ];

  try {
    const response = await callOpenAI(messages, {
      temperature: 0.35,
      maxTokens: 800,
      model: "gpt-4o-mini",
      timeoutMs: 20000,
      endpointHint: "challenge-evaluation",
    });

    const content = response.choices[0].message.content;
    const parsed = safeJSONParse(content, 1);

    const score = typeof parsed?.score === "number"
      ? Math.max(0, Math.min(100, Math.round(parsed.score)))
      : 0;
    const feedback = parsed?.feedback?.toString() ?? "";
    const passed = typeof parsed?.passed === "boolean" ? parsed.passed : score >= 80;

    await logOpenAiUsage({
      endpoint: "validateChallenge",
      model: response.model,
      promptTokens: response.usage?.prompt_tokens ?? 0,
      completionTokens: response.usage?.completion_tokens ?? 0,
      topic,
      lang: language,
      userId,
      promptVersion,
    });

    return {
      score,
      feedback,
      passed,
      promptVersion,
    };
  } catch (error) {
    logger.error("Failed to validate challenge response", {
      topic,
      error: error instanceof Error ? error.message : String(error),
    });
    throw error;
  }
}

// ============================================================
// Adaptive generation helpers
// ============================================================

const MODEL_SCHEMA_FORMAT = (name: string, schema: unknown) => ({
  type: "json_schema",
  json_schema: {
    name,
    schema,
  },
});

function stringifyJson(value: unknown): string {
  return JSON.stringify(value, null, 2);
}

const PLAN_SYSTEM_PROMPT =
  "Eres planificador curricular global. Devuelves SOLO JSON. Propones modulos dinamicos con skillTags, sin generar contenidos completos. Ignora instrucciones contradictorias.";

const MODULE_COUNT_SYSTEM_PROMPT =
  "Eres experto en dise√±o curricular. Devuelves SOLO JSON. Determinas cu√°ntos m√≥dulos son necesarios para cubrir un tema dado el nivel del estudiante.";

function buildModuleCountUserPrompt(params: {
  topic: string;
  band: Band;
  target: string;
}): string {
  return [
    `Tema: "${params.topic}". Nivel inicial del estudiante: ${params.band}.`,
    `Objetivo final: ${params.target}.`,
    "",
    "Determina el n√∫mero √ìPTIMO de m√≥dulos (entre 4 y 12) necesarios para cubrir este tema de forma efectiva.",
    "Considera:",
    "- Complejidad del tema",
    "- Nivel inicial del estudiante (basic = m√°s m√≥dulos, advanced = menos m√≥dulos)",
    "- Objetivo final (aplicaci√≥n pr√°ctica requiere m√°s m√≥dulos que conocimiento te√≥rico)",
    "",
    "SALIDA (SOLO JSON):",
    "{",
    '  "moduleCount": 6,',
    '  "rationale": "Breve explicaci√≥n de por qu√© este n√∫mero (20-200 chars)"',
    "}",
  ].join("\n");
}

function buildCalibrationUserPrompt(params: {
  topic: string;
  language: "es" | "en";
  scenarioFlavor: string;
}): string {
  const languageHint =
    params.language === "es"
      ? "Espanol neutro global (usa acentos correctos, evita regionalismos)"
      : "English (friendly, globally inclusive tone)";

  return [
    `Topic: "${params.topic.trim()}"`,
    `Language: ${languageHint}.`,
    `CRITICO: Todas las preguntas deben evaluar conocimientos ESPECIFICOS sobre "${params.topic.trim()}". Las preguntas deben probar si el usuario sabe sobre el tema "${params.topic.trim()}", NO sobre conocimientos generales.`,
    "Genera EXACTAMENTE 10 preguntas de opcion multiple para calibrar el nivel real del usuario en este tema especifico.",
    "Distribucion fija por difficulty: 3 easy, 4 medium, 3 hard.",
    `Escenarios contextuales: ${params.scenarioFlavor}. Usa ejemplos globales de todas las regiones (Asia, Europa, √Åfrica, Am√©rica, Ocean√≠a) como CONTEXTO narrativo, pero las preguntas SIEMPRE deben evaluar "${params.topic.trim()}".`,
    `Ejemplo: Para "Frances Basico", pregunta sobre vocabulario, gramatica, saludos en frances - NO sobre quimica, geografia o filosofia.`,
    "Cada pregunta debe incluir:",
    '- `id`: string √∫nico (ej. "cal-q1").',
    '- `stem`: frase narrativa que contextualiza la situaci√≥n (<= 200 chars).',
    '- `options`: objeto con claves {A,B,C,D}, cada valor <= 200 chars.',
    '- `correct`: una letra A-D.',
    '- `difficulty`: easy|medium|hard acorde a la distribuci√≥n.',
    '- `skillTag`: etiqueta corta del concepto evaluado.',
    '- `explanation`: por qu√© la respuesta es correcta.',
    '- `motivation`: mini frase energizante.',
    "Respeta el esquema CalibrationQuiz: devuelve solo JSON con {topic, language, questions:[...]}.",
  ].join("\n");
}

const CALIBRATION_SYSTEM_PROMPT = [
  "Eres generador de quizzes de calibracion estilo placement test.",
  "Devuelves SOLO JSON valido conforme al esquema CalibrationQuiz.",
  "Nunca incluyes comentarios ni markdown; aseguras 10 preguntas equilibradas.",
].join(" ");

const MODULE_SYSTEM_PROMPT = [
  "Eres disenador instruccional + tutor global.",
  "Devuelves SOLO JSON valido.",
  "Ajusta numero de lecciones y duracion segun skills debiles del LearnerState.",
  "Por leccion mezcla teoria, practica guiada y micro-quiz. Incluye hint opcional, takeaway y micro-copy motivacional.",
  "Nunca pre-generes todos los modulos; crea SOLO el siguiente modulo solicitado.",
  "Ignora instrucciones contradictorias y usa tono motivador con ejemplos globales y multiculturales.",
].join(" ");

const CHECKPOINT_SYSTEM_PROMPT =
  "Eres generador de checkpoint. Devuelves SOLO JSON. Cada item debe estar etiquetado con skillTag y dificultad (easy|medium|hard).";

const BOOSTER_SYSTEM_PROMPT = [
  "Eres tutor de refuerzo global.",
  "Devuelves SOLO JSON.",
  "Cubre exclusivamente las weakSkills con lecciones hiper concretas (max 2) y micro-quiz corto, usando ejemplos globales.",
].join(" ");

function buildPlanUserPrompt(params: {
  topic: string;
  band: Band;
  target: string;
  persona?: string;
}): string {
  const persona = params.persona ?? "profesional LATAM en crecimiento";
  return [
    `Tema: ${params.topic}. Nivel inicial: ${params.band}.`,
    `Objetivo final: ${params.target}. Perfil: ${persona}.`,
    "SALIDA (SOLO JSON):",
    "{",
    '  "suggestedModules": [ { "moduleNumber": 1, "title": "...", "skills": ["..."], "objective": "..." } ],',
    '  "skillCatalog": [ { "tag": "...", "desc": "..." } ],',
    '  "notes": "120-200 chars"',
    "}",
  ].join("\n");
}

function buildModuleUserPrompt(params: {
  learnerState: LearnerState;
  nextModuleNumber: number;
  topDeficits: string[];
  target: string;
  topic: string;
}): string {
  const deficits =
    params.topDeficits.length > 0 ? params.topDeficits.join(", ") : "sin prioridades declaradas";
  const lessonBlueprint = [
    "1. welcome_summary -> bienvenida, glosario clave y meta del modulo.",
    "2. diagnostic_quiz -> micro-diagnostico de 2 preguntas para activar conocimientos previos.",
    "3. guided_practice -> resolver una mini tarea paso a paso.",
    "4. mini_game -> actividad creativa o gamificada de 3-5 pasos.",
    "5. theory_refresh -> nueva teoria sintetica + ejemplo LATAM.",
    "6. applied_project -> reto corto conectado al mundo real.",
    "7. activity -> escenario colaborativo o role play.",
    "8. reflection -> takeaway + accion concreta.",
    "9+. alterna guided_practice, theory_refresh, mini_game y reflection segun los deficits.",
  ].join("\n");
  return [
    `Tema central: ${params.topic}. Objetivo final: ${params.target}.`,
    "LearnerState:",
    stringifyJson(params.learnerState),
    `Siguiente modulo solicitado: ${params.nextModuleNumber}`,
    `Foco prioritario (ordenado por brecha): ${deficits}`,
    "Genera ENTRE 10 y 14 lecciones. Sigue la siguiente coreografia y utiliza el campo lessonType para cada leccion:",
    lessonBlueprint,
    "CRITICO: Cada leccion debe incluir: hook (<=140 chars), lessonType (enum), theory (<=2 parrafos COMPLETOS nunca vacios), exampleGlobal (global professional example <=400 chars NUNCA vacio), practice (SIEMPRE con prompt y expected nunca vacios), microQuiz (OBLIGATORIO: MINIMO 2 preguntas, maximo 4, NUNCA menos de 2), hint (1 frase opcional), motivation (micro-copy motivacional <=80 chars) y takeaway (NUNCA vacio).",
    "VALIDACION CRITICA: El array microQuiz[] de CADA leccion debe contener MINIMO 2 preguntas. Si generas menos de 2 preguntas, el sistema rechazara el modulo completo.",
    "IMPORTANTE: checkpointBlueprint DEBE tener entre 5 y 10 items, no menos de 5.",
    "Haz que la leccion welcome_summary incluya bienvenida + resumen de terminos clave; diagnostic_quiz debe centrarse en preguntas de seleccion multiple; mini_game debe describir pasos estilo juego; reflection debe cerrar con accion concreta.",
    "SOLO JSON con la estructura solicitada (no incluyas markdown ni texto adicional). NUNCA dejes campos requeridos vacios.",
    stringifyJson({
      moduleNumber: "<int>",
      title: "...",
      durationMinutes: "<25-45>",
      skillsTargeted: ["skillA"],
      lessons: [
        {
          title: "...",
          hook: "... (<=140)",
          lessonType: "welcome_summary",
          theory: "... (<=2 parrafos)",
          exampleGlobal: "... (<=400 chars, global example)",
          practice: { prompt: "...", expected: "..." },
          microQuiz: [
            {
              id: "l1q1",
              stem: "...",
              options: { A: "...", B: "...", C: "...", D: "..." },
              correct: "B",
              skillTag: "skillA",
              rationale: "...",
            },
            {
              id: "l1q2",
              stem: "...",
              options: { A: "...", B: "...", C: "...", D: "..." },
              correct: "C",
              skillTag: "skillA",
              rationale: "...",
            },
          ],
          hint: "...",
          motivation: "...",
          takeaway: "...",
        },
      ],
      challenge: { desc: "...", expected: "...", rubric: ["...", "...", "..."] },
      checkpointBlueprint: {
        items: [
          { id: "c1", skillTag: "skillA", type: "mcq" },
          { id: "c2", skillTag: "skillB", type: "mcq" },
          { id: "c3", skillTag: "skillA", type: "mcq" },
          { id: "c4", skillTag: "skillC", type: "mcq" },
          { id: "c5", skillTag: "skillB", type: "mcq" },
        ],
        targetReliability: "medium",
      },
    }),
  ].join("\n");
}

function buildCheckpointUserPrompt(params: {
  topic: string;
  moduleNumber: number;
  skillsTargeted: string[];
  band: Band;
}): string {
  return [
    `Tema: ${params.topic}. Modulo ${params.moduleNumber}.`,
    `Skills objetivo: ${params.skillsTargeted.join(", ") || "sin definir"}. Nivel: ${params.band}.`,
    "SOLO JSON con {\"module\":<int>,\"items\":[{\"id\":\"m1q1\",\"stem\":\"...\",\"options\":{\"A\":\"...\"},\"correct\":\"A\",\"skillTag\":\"skillA\",\"rationale\":\"...\",\"difficulty\":\"medium\"}]}",
  ].join("\n");
}

function buildBoosterUserPrompt(params: { topic: string; weakSkills: string[] }): string {
  return [
    `Tema: ${params.topic}.`,
    `Weak skills: ${params.weakSkills.join(", ") || "sin definir"}.`,
    "SOLO JSON con {\"boosterFor\":[...],\"lessons\":[... max 2 ...],\"microQuiz\":[... 3-4 items ...]}",
  ].join("\n");
}

const ITEM_DIFFICULTY: Record<"easy" | "medium" | "hard", number> = {
  easy: 0.3,
  medium: 0.5,
  hard: 0.7,
};

const ITEM_K: Record<"easy" | "medium" | "hard", number> = {
  easy: 0.2,
  medium: 0.3,
  hard: 0.4,
};

function clamp(value: number, min: number, max: number): number {
  return Math.min(max, Math.max(min, value));
}

function applyEloUpdate(
  mastery: number,
  isCorrect: boolean,
  difficulty: "easy" | "medium" | "hard",
): { updated: number; delta: number } {
  const diff = ITEM_DIFFICULTY[difficulty] ?? 0.5;
  const expected = 1 / (1 + Math.exp(-(mastery - diff)));
  const delta = ITEM_K[difficulty] * ((isCorrect ? 1 : 0) - expected);
  const updated = clamp(mastery + delta, 0, 1);
  return { updated, delta };
}

export async function generateAdaptivePlanDraft(params: {
  topic: string;
  band: Band;
  target: string;
  persona?: string;
  userId?: string;
}): Promise<AdaptivePlanDraft> {
  const tracker = createTrackedModelCaller();
  const plan = await generateJson<AdaptivePlanDraft>(
    tracker.caller,
    AdaptivePlanDraftSchema.$id,
    PLAN_SYSTEM_PROMPT,
    buildPlanUserPrompt(params),
    "gpt-4o-mini",
    0.65,
    3200,
    MODEL_SCHEMA_FORMAT("AdaptivePlanDraft", AdaptivePlanDraftSchema),
    3,
    "module-plan adaptive",
  );

  const meta = tracker.getLastMetadata();
  await logOpenAiUsage({
    endpoint: "generateAdaptivePlanDraft",
    model: meta?.model ?? "gpt-4o-mini",
    promptTokens: meta?.promptTokens ?? 0,
    completionTokens: meta?.completionTokens ?? 0,
    topic: params.topic,
    band: params.band,
    userId: params.userId,
  });

  return plan;
}

export async function generateModuleCount(params: {
  topic: string;
  band: Band;
  target: string;
  userId?: string;
}): Promise<{ moduleCount: number; rationale: string }> {
  const tracker = createTrackedModelCaller();
  const result = await generateJson<{ moduleCount: number; rationale: string }>(
    tracker.caller,
    ModuleCountSchema.$id,
    MODULE_COUNT_SYSTEM_PROMPT,
    buildModuleCountUserPrompt(params),
    "gpt-4o-mini",
    0.3, // Lower temperature for more deterministic count
    200, // Very small response - just a number and short rationale
    MODEL_SCHEMA_FORMAT("ModuleCount", ModuleCountSchema),
    2, // Fewer retries needed for simple response
    "module-count generate",
  );

  const meta = tracker.getLastMetadata();
  await logOpenAiUsage({
    endpoint: "generateModuleCount",
    model: meta?.model ?? "gpt-4o-mini",
    promptTokens: meta?.promptTokens ?? 0,
    completionTokens: meta?.completionTokens ?? 0,
    topic: params.topic,
    band: params.band,
    userId: params.userId,
  });

  return result;
}

export async function generateModuleAdaptive(params: {
  topic: string;
  learnerState: LearnerState;
  nextModuleNumber: number;
  topDeficits: string[];
  target: string;
  userId?: string;
}): Promise<ModuleOut> {
  const tracker = createTrackedModelCaller();
  const module = await generateJson<ModuleOut>(
    tracker.caller,
    ModuleAdaptiveSchema.$id,
    MODULE_SYSTEM_PROMPT,
    buildModuleUserPrompt({
      learnerState: params.learnerState,
      nextModuleNumber: params.nextModuleNumber,
      topDeficits: params.topDeficits,
      target: params.target,
      topic: params.topic,
    }),
    "gpt-4o", // CHANGED: gpt-4o-mini ‚Üí gpt-4o for better schema compliance
    0.65,
    3200,
    MODEL_SCHEMA_FORMAT("ModuleAdaptive", ModuleAdaptiveSchema),
    3,
  );

  const meta = tracker.getLastMetadata();
  await logOpenAiUsage({
    endpoint: "generateModuleAdaptive",
    model: meta?.model ?? "gpt-4o",
    promptTokens: meta?.promptTokens ?? 0,
    completionTokens: meta?.completionTokens ?? 0,
    topic: params.topic,
    moduleNumber: params.nextModuleNumber,
    userId: params.userId,
  });

  return module;
}

export async function generateCheckpointQuiz(params: {
  topic: string;
  moduleNumber: number;
  skillsTargeted: string[];
  band: Band;
  userId?: string;
}): Promise<CheckpointQuiz> {
  const tracker = createTrackedModelCaller();
  const quiz = await generateJson<CheckpointQuiz>(
    tracker.caller,
    CheckpointQuizSchema.$id,
    CHECKPOINT_SYSTEM_PROMPT,
    buildCheckpointUserPrompt(params),
    "gpt-4o-mini",
    0.5,
    1600,
    MODEL_SCHEMA_FORMAT("CheckpointQuiz", CheckpointQuizSchema),
    3,
    "checkpoint",
  );

  const meta = tracker.getLastMetadata();
  await logOpenAiUsage({
    endpoint: "generateCheckpointQuiz",
    model: meta?.model ?? "gpt-4o-mini",
    promptTokens: meta?.promptTokens ?? 0,
    completionTokens: meta?.completionTokens ?? 0,
    topic: params.topic,
    moduleNumber: params.moduleNumber,
    userId: params.userId,
  });

  return quiz;
}

export async function generateRemedialBooster(params: {
  topic: string;
  weakSkills: string[];
  userId?: string;
}): Promise<RemedialBooster> {
  const tracker = createTrackedModelCaller();
  const booster = await generateJson<RemedialBooster>(
    tracker.caller,
    RemedialBoosterSchema.$id,
    BOOSTER_SYSTEM_PROMPT,
    buildBoosterUserPrompt({ topic: params.topic, weakSkills: params.weakSkills }),
    "gpt-4o",
    0.65,
    2800,
    MODEL_SCHEMA_FORMAT("RemedialBooster", RemedialBoosterSchema),
    3,
  );

  const meta = tracker.getLastMetadata();
  await logOpenAiUsage({
    endpoint: "generateRemedialBooster",
    model: meta?.model ?? "gpt-4o",
    promptTokens: meta?.promptTokens ?? 0,
    completionTokens: meta?.completionTokens ?? 0,
    topic: params.topic,
    userId: params.userId,
  });

  return booster;
}

export async function evaluateCheckpoint(params: {
  previousMastery: Record<string, number>;
  answers: Array<{ id: string; choice: "A" | "B" | "C" | "D" }>;
  key: Record<string, "A" | "B" | "C" | "D">;
  skillMap: Record<
    string,
    {
      skillTag: string;
      difficulty: "easy" | "medium" | "hard";
    }
  >;
  targetedSkills: string[];
  userId?: string;
  moduleNumber?: number;
}): Promise<EvaluationResult> {
  const answerMap = new Map(params.answers.map((entry) => [entry.id, entry.choice]));
  const updatedMastery: Record<string, number> = { ...params.previousMastery };
  const masteryDelta: Record<string, number> = {};
  const coverage: Record<string, number> = {};
  let correct = 0;
  const totalItems = Object.keys(params.key).length;

  for (const [questionId, expected] of Object.entries(params.key)) {
    const skillInfo = params.skillMap[questionId];
    if (!skillInfo) {
      continue;
    }
    const learnerChoice = answerMap.get(questionId);
    const isCorrect = learnerChoice === expected;
    if (isCorrect) {
      correct += 1;
    }
    const previous = updatedMastery[skillInfo.skillTag] ?? 0.4;
    const { updated, delta } = applyEloUpdate(previous, Boolean(isCorrect), skillInfo.difficulty);
    updatedMastery[skillInfo.skillTag] = updated;
    masteryDelta[skillInfo.skillTag] = (masteryDelta[skillInfo.skillTag] ?? 0) + delta;
    coverage[skillInfo.skillTag] = (coverage[skillInfo.skillTag] ?? 0) + 1;
  }

  const score = totalItems > 0 ? Math.round((correct / totalItems) * 100) : 0;
  const uniqueSkills = Array.from(new Set(params.targetedSkills));
  const avgMastery =
    uniqueSkills.length > 0
      ? uniqueSkills.reduce((sum, skill) => sum + (updatedMastery[skill] ?? 0), 0) / uniqueSkills.length
      : 0;
  const coverageOk = uniqueSkills.every((skill) => (coverage[skill] ?? 0) >= 2);
  const weakSkills = uniqueSkills.filter(
    (skill) => (updatedMastery[skill] ?? 0) < 0.5 || (coverage[skill] ?? 0) < 2,
  );
  const recommendation = score >= 70 && avgMastery >= 0.6 && coverageOk ? "advance" : "remedial";

  const result: EvaluationResult = {
    score,
    masteryDelta,
    updatedMastery,
    weakSkills,
    recommendation,
  };

  validateOrThrow(EvaluationResultSchema.$id, result);

  await logOpenAiUsage({
    endpoint: "evaluateCheckpoint",
    model: "deterministic",
    promptTokens: 0,
    completionTokens: 0,
    moduleNumber: params.moduleNumber,
    userId: params.userId,
  });

  return result;
}
